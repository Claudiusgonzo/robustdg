{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction code for MatchDG\n",
    "\n",
    "### Paper: Domain Generalization using Causal Matching [Arxiv](https://arxiv.org/abs/2006.07500)\n",
    "\n",
    "The following code reproduces results for Rotated MNIST and Fashion-MNIST datasets, corresponding to Tables 1, 2 and 3 in the paper.\n",
    "\n",
    "For convenience, we provide the exact commands for Rotated MNIST dataset with training domains set to [15, 30, 45, 60, 75] and the test domains set to [0, 90]. \n",
    "\n",
    "To obtain results for the FashionMNIST dataset, change the dataset parameter `--dataset` from `rot_mnist` to `fashion_mnist`.\n",
    "\n",
    "To obtain results for the different set of training domains in the paper, change the input to the parameter `--train_domains` with the list of training domains: `--train_domains [30, 45]` or `--train_domains [30, 45, 60]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/t-dimaha/RobustDG/robustdg\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "From the directory `data/rot_mnist`, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/rot_mnist\n",
    "python data_gen.py resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1\n",
    "Now move back to the root directory.\n",
    "\n",
    "* ERM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  195 0 0\n",
      "Max Class Size:  229 0 1\n",
      "Max Class Size:  206 0 2\n",
      "Max Class Size:  204 0 3\n",
      "Max Class Size:  192 0 4\n",
      "Max Class Size:  178 0 5\n",
      "Max Class Size:  212 0 6\n",
      "Max Class Size:  211 0 7\n",
      "Max Class Size:  172 0 8\n",
      "Max Class Size:  201 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "Base Domain:  195 0 0\n",
      "Base Domain:  229 0 1\n",
      "Base Domain:  206 0 2\n",
      "Base Domain:  204 0 3\n",
      "Base Domain:  192 0 4\n",
      "Base Domain:  178 0 5\n",
      "Base Domain:  212 0 6\n",
      "Base Domain:  211 0 7\n",
      "Base Domain:  172 0 8\n",
      "Base Domain:  201 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  150.15661907196045 4022.5083558261395\n",
      "Train Acc Env :  59.35\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  29.6810018196702 6545.232803344727\n",
      "Train Acc Env :  95.3\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  16.288636343553662 6988.222728729248\n",
      "Train Acc Env :  97.05\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  10.980664486065507 7379.438438415527\n",
      "Train Acc Env :  98.75\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  6.416184247471392 8008.8325843811035\n",
      "Train Acc Env :  99.2\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  5.20461905375123 8589.451194763184\n",
      "Train Acc Env :  99.45\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  4.200245687039569 8664.314785003662\n",
      "Train Acc Env :  99.55\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.8405057557392865 8733.66635131836\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.1262082264292985 8828.022956848145\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.5478129678522237 9267.322345733643\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.213427290902473 9172.205947875977\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.3803303997265175 9671.832859039307\n",
      "Train Acc Env :  99.6\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.8904681682470255 9194.810913085938\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.6283219456090592 9174.568119049072\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5414112075814046 9283.009456634521\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  14\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  223 0 0\n",
      "Max Class Size:  235 0 1\n",
      "Max Class Size:  191 0 2\n",
      "Max Class Size:  212 0 3\n",
      "Max Class Size:  183 0 4\n",
      "Max Class Size:  210 0 5\n",
      "Max Class Size:  191 0 6\n",
      "Max Class Size:  202 0 7\n",
      "Max Class Size:  181 0 8\n",
      "Max Class Size:  172 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "Base Domain:  223 0 0\n",
      "Base Domain:  235 0 1\n",
      "Base Domain:  191 0 2\n",
      "Base Domain:  212 0 3\n",
      "Base Domain:  183 0 4\n",
      "Base Domain:  210 0 5\n",
      "Base Domain:  191 0 6\n",
      "Base Domain:  202 0 7\n",
      "Base Domain:  181 0 8\n",
      "Base Domain:  172 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  152.00036534667015 4040.9632254987955\n",
      "Train Acc Env :  60.7\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  33.18137834221125 6619.0585289001465\n",
      "Train Acc Env :  92.35\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  16.892514562234282 6739.208896636963\n",
      "Train Acc Env :  97.0\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  10.346020901575685 7364.359020233154\n",
      "Train Acc Env :  98.45\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  6.981843613553792 7915.556728363037\n",
      "Train Acc Env :  99.05\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  4.613111946731806 8321.706874847412\n",
      "Train Acc Env :  99.35\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.7969816693803295 8420.824962615967\n",
      "Train Acc Env :  99.75\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.9577327540609986 8732.170875549316\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.5315993943950161 8753.670608520508\n",
      "Train Acc Env :  99.85\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.1600122048985213 8995.680179595947\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.9852112175431103 8950.170166015625\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.104290203889832 9070.314144134521\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.8767369174747728 9105.641693115234\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5208963884797413 8828.166446685791\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.7159060535195749 9041.815956115723\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  14\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  206 0 0\n",
      "Max Class Size:  242 0 1\n",
      "Max Class Size:  182 0 2\n",
      "Max Class Size:  209 0 3\n",
      "Max Class Size:  179 0 4\n",
      "Max Class Size:  194 0 5\n",
      "Max Class Size:  189 0 6\n",
      "Max Class Size:  201 0 7\n",
      "Max Class Size:  198 0 8\n",
      "Max Class Size:  200 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "Base Domain:  206 0 0\n",
      "Base Domain:  242 0 1\n",
      "Base Domain:  182 0 2\n",
      "Base Domain:  209 0 3\n",
      "Base Domain:  179 0 4\n",
      "Base Domain:  194 0 5\n",
      "Base Domain:  189 0 6\n",
      "Base Domain:  201 0 7\n",
      "Base Domain:  198 0 8\n",
      "Base Domain:  200 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  150.37606190145016 3769.2717136591673\n",
      "Train Acc Env :  59.95\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  28.25320729240775 6640.257129669189\n",
      "Train Acc Env :  94.45\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  16.08192825689912 7246.867958068848\n",
      "Train Acc Env :  97.45\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  10.596211474388838 7917.861793518066\n",
      "Train Acc Env :  98.05\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  5.816339531447738 8382.732833862305\n",
      "Train Acc Env :  99.1\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  3.8612781376577914 8610.234172821045\n",
      "Train Acc Env :  99.7\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  4.9804622316733 9122.544563293457\n",
      "Train Acc Env :  99.5\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  3.0566918367985636 9247.140808105469\n",
      "Train Acc Env :  99.65\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.4820738192647696 9110.940212249756\n",
      "Train Acc Env :  99.85\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.2355088134063408 9091.393264770508\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.8817758770892397 9250.347805023193\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.1459617250366136 9329.095264434814\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.3094260026118718 9503.68510055542\n",
      "Train Acc Env :  99.85\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.6027483302750625 9183.664581298828\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.4365620322932955 9113.807857513428\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  14\n",
      "\n",
      "\n",
      "Done for the Model..\n",
      "Final Test Accuracy nan nan\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python train.py --dataset rot_mnist --method_name erm_match --match_case 0.01 --penalty_ws 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ERM_RandomMatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python train.py --dataset rot_mnist --method_name erm_match --match_case 0.01 --penalty_ws 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ERM_PerfectMatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python train.py --dataset rot_mnist --method_name erm_match --match_case 1.0 --penalty_ws 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MatchDG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  195 0 0\n",
      "Max Class Size:  229 0 1\n",
      "Max Class Size:  206 0 2\n",
      "Max Class Size:  204 0 3\n",
      "Max Class Size:  192 0 4\n",
      "Max Class Size:  178 0 5\n",
      "Max Class Size:  212 0 6\n",
      "Max Class Size:  211 0 7\n",
      "Max Class Size:  172 0 8\n",
      "Max Class Size:  201 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "Base Domain:  195 0 0\n",
      "Base Domain:  229 0 1\n",
      "Base Domain:  206 0 2\n",
      "Base Domain:  204 0 3\n",
      "Base Domain:  192 0 4\n",
      "Base Domain:  178 0 5\n",
      "Base Domain:  212 0 6\n",
      "Base Domain:  211 0 7\n",
      "Base Domain:  172 0 8\n",
      "Base Domain:  201 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2302374428672.0 0.0 6835.630554199219\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2299881316352.0 0.0 6828.699035644531\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2300393857024.0 0.0 6812.87890625\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2300901081088.0 0.0 6805.82763671875\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2298242777088.0 0.0 6797.289825439453\n",
      "Done Training for epoch:  4\n",
      "Base Domain:  195 0 0\n",
      "Base Domain:  229 0 1\n",
      "Base Domain:  206 0 2\n",
      "Base Domain:  204 0 3\n",
      "Base Domain:  192 0 4\n",
      "Base Domain:  178 0 5\n",
      "Base Domain:  212 0 6\n",
      "Base Domain:  211 0 7\n",
      "Base Domain:  172 0 8\n",
      "Base Domain:  201 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2381601865728.0 0.0 5027.657897949219\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2379205484544.0 0.0 5018.397308349609\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2382225465344.0 0.0 5009.978302001953\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2380251250688.0 0.0 5001.687042236328\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2380632309760.0 0.0 4995.195709228516\n",
      "Done Training for epoch:  9\n",
      "Base Domain:  195 0 0\n",
      "Base Domain:  229 0 1\n",
      "Base Domain:  206 0 2\n",
      "Base Domain:  204 0 3\n",
      "Base Domain:  192 0 4\n",
      "Base Domain:  178 0 5\n",
      "Base Domain:  212 0 6\n",
      "Base Domain:  211 0 7\n",
      "Base Domain:  172 0 8\n",
      "Base Domain:  201 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2380539830272.0 0.0 4986.87646484375\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2376417296384.0 0.0 4978.481475830078\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2378557022208.0 0.0 4970.926361083984\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2377506004992.0 0.0 4964.3096923828125\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2377934413824.0 0.0 4955.118103027344\n",
      "Done Training for epoch:  14\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  223 0 0\n",
      "Max Class Size:  235 0 1\n",
      "Max Class Size:  191 0 2\n",
      "Max Class Size:  212 0 3\n",
      "Max Class Size:  183 0 4\n",
      "Max Class Size:  210 0 5\n",
      "Max Class Size:  191 0 6\n",
      "Max Class Size:  202 0 7\n",
      "Max Class Size:  181 0 8\n",
      "Max Class Size:  172 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "Base Domain:  223 0 0\n",
      "Base Domain:  235 0 1\n",
      "Base Domain:  191 0 2\n",
      "Base Domain:  212 0 3\n",
      "Base Domain:  183 0 4\n",
      "Base Domain:  210 0 5\n",
      "Base Domain:  191 0 6\n",
      "Base Domain:  202 0 7\n",
      "Base Domain:  181 0 8\n",
      "Base Domain:  172 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2270857355264.0 0.0 7040.103729248047\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2268258189312.0 0.0 7033.040130615234\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2268416040960.0 0.0 7012.241912841797\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2266892615680.0 0.0 7001.000732421875\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2271862677504.0 0.0 7006.6168212890625\n",
      "Done Training for epoch:  4\n",
      "Base Domain:  223 0 0\n",
      "Base Domain:  235 0 1\n",
      "Base Domain:  191 0 2\n",
      "Base Domain:  212 0 3\n",
      "Base Domain:  183 0 4\n",
      "Base Domain:  210 0 5\n",
      "Base Domain:  191 0 6\n",
      "Base Domain:  202 0 7\n",
      "Base Domain:  181 0 8\n",
      "Base Domain:  172 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2343831674880.0 0.0 4837.907806396484\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2348075016192.0 0.0 4828.637786865234\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2345573507072.0 0.0 4822.850158691406\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2348175507456.0 0.0 4811.026794433594\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2343770488832.0 0.0 4806.598571777344\n",
      "Done Training for epoch:  9\n",
      "Base Domain:  223 0 0\n",
      "Base Domain:  235 0 1\n",
      "Base Domain:  191 0 2\n",
      "Base Domain:  212 0 3\n",
      "Base Domain:  183 0 4\n",
      "Base Domain:  210 0 5\n",
      "Base Domain:  191 0 6\n",
      "Base Domain:  202 0 7\n",
      "Base Domain:  181 0 8\n",
      "Base Domain:  172 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2345884704768.0 0.0 4797.517852783203\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2348389335040.0 0.0 4791.922790527344\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2344761122816.0 0.0 4782.544097900391\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2347882299392.0 0.0 4776.169250488281\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2345800040448.0 0.0 4769.43505859375\n",
      "Done Training for epoch:  14\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  206 0 0\n",
      "Max Class Size:  242 0 1\n",
      "Max Class Size:  182 0 2\n",
      "Max Class Size:  209 0 3\n",
      "Max Class Size:  179 0 4\n",
      "Max Class Size:  194 0 5\n",
      "Max Class Size:  189 0 6\n",
      "Max Class Size:  201 0 7\n",
      "Max Class Size:  198 0 8\n",
      "Max Class Size:  200 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "Base Domain:  206 0 0\n",
      "Base Domain:  242 0 1\n",
      "Base Domain:  182 0 2\n",
      "Base Domain:  209 0 3\n",
      "Base Domain:  179 0 4\n",
      "Base Domain:  194 0 5\n",
      "Base Domain:  189 0 6\n",
      "Base Domain:  201 0 7\n",
      "Base Domain:  198 0 8\n",
      "Base Domain:  200 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2290012479488.0 0.0 7078.821350097656\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2294086246400.0 0.0 7062.387512207031\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2288734830592.0 0.0 7054.804473876953\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2295047356416.0 0.0 7052.055816650391\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2291565199360.0 0.0 7037.969757080078\n",
      "Done Training for epoch:  4\n",
      "Base Domain:  206 0 0\n",
      "Base Domain:  242 0 1\n",
      "Base Domain:  182 0 2\n",
      "Base Domain:  209 0 3\n",
      "Base Domain:  179 0 4\n",
      "Base Domain:  194 0 5\n",
      "Base Domain:  189 0 6\n",
      "Base Domain:  201 0 7\n",
      "Base Domain:  198 0 8\n",
      "Base Domain:  200 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2352984809472.0 0.0 4966.5572509765625\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2346493779968.0 0.0 4957.283172607422\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2351597264896.0 0.0 4951.102081298828\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2347387740160.0 0.0 4941.510833740234\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2349774512128.0 0.0 4934.8707275390625\n",
      "Done Training for epoch:  9\n",
      "Base Domain:  206 0 0\n",
      "Base Domain:  242 0 1\n",
      "Base Domain:  182 0 2\n",
      "Base Domain:  209 0 3\n",
      "Base Domain:  179 0 4\n",
      "Base Domain:  194 0 5\n",
      "Base Domain:  189 0 6\n",
      "Base Domain:  201 0 7\n",
      "Base Domain:  198 0 8\n",
      "Base Domain:  200 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2348477718528.0 0.0 4928.645294189453\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2352642039808.0 0.0 4921.148956298828\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2350757986304.0 0.0 4910.516052246094\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2353742282752.0 0.0 4906.272613525391\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  16 torch.Size([128, 5, 1, 224, 224]) 16\n",
      "Train Loss Ctr :  0.0 2350882955264.0 0.0 4893.922912597656\n",
      "Done Training for epoch:  14\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  195 0 0\n",
      "Max Class Size:  229 0 1\n",
      "Max Class Size:  206 0 2\n",
      "Max Class Size:  204 0 3\n",
      "Max Class Size:  192 0 4\n",
      "Max Class Size:  178 0 5\n",
      "Max Class Size:  212 0 6\n",
      "Max Class Size:  211 0 7\n",
      "Max Class Size:  172 0 8\n",
      "Max Class Size:  201 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Base Domain:  195 0 0\n",
      "Base Domain:  229 0 1\n",
      "Base Domain:  206 0 2\n",
      "Base Domain:  204 0 3\n",
      "Base Domain:  192 0 4\n",
      "Base Domain:  178 0 5\n",
      "Base Domain:  212 0 6\n",
      "Base Domain:  211 0 7\n",
      "Base Domain:  172 0 8\n",
      "Base Domain:  201 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  118.82023015618324 112.55427277088165 2267.645241640508\n",
      "Train Acc Env :  68.65\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  20.850172951817513 19.41031998768449 1887.3213577270508\n",
      "Train Acc Env :  95.95\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  14.584679767489433 10.242182621732354 1112.847261428833\n",
      "Train Acc Env :  98.0\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  10.344196803867817 6.788934767246246 736.1488783359528\n",
      "Train Acc Env :  98.95\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  7.878314204514027 5.210508739575744 519.3159873485565\n",
      "Train Acc Env :  99.25\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  5.87250042706728 4.218225893564522 390.8740680217743\n",
      "Train Acc Env :  99.4\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  4.9984544813632965 3.195353058166802 281.6822234392166\n",
      "Train Acc Env :  99.55\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  3.9082437455654144 2.3035729695111513 213.3182864189148\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.9037334471940994 1.9112323243170977 168.97152823209763\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  3.187946490943432 1.8685060553252697 142.1767520904541\n",
      "Train Acc Env :  99.7\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.798855021595955 1.7007896364666522 123.74919205904007\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.3738852590322495 1.415102387778461 103.6655635535717\n",
      "Train Acc Env :  99.85\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.13783311098814 1.2423513256944716 85.65944430232048\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.951315388083458 1.034805838484317 71.52020418643951\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.4758240282535553 1.0513713594991714 63.04751056432724\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  14\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Base Domain:  195 0 0\n",
      "Base Domain:  229 0 1\n",
      "Base Domain:  206 0 2\n",
      "Base Domain:  204 0 3\n",
      "Base Domain:  192 0 4\n",
      "Base Domain:  178 0 5\n",
      "Base Domain:  212 0 6\n",
      "Base Domain:  211 0 7\n",
      "Base Domain:  172 0 8\n",
      "Base Domain:  201 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.9567088782787323 0.45979833375895396 139.94559678435326\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.6775788515806198 0.2855981115135364 95.31189158558846\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.7875865995883942 0.7854107020539232 161.5362972319126\n",
      "Train Acc Env :  99.7\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.6758556962013245 0.33137308520963416 71.29310151934624\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.4146703779697418 0.282703984354157 43.760812014341354\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.41875773668289185 0.22343317337799817 37.0856397151947\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.41248343884944916 0.22914230223977938 33.879189401865005\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.7060320228338242 0.31496277143014595 48.800896510481834\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.44948358833789825 0.3141586609999649 34.68388803303242\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.49297887086868286 0.2532875176984817 30.246539622545242\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5029304921627045 0.3068777918815613 33.87940354645252\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5193255543708801 0.31985055143013597 32.11047284305096\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5811407417058945 0.3613489397102967 33.41546908020973\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5955804884433746 0.39321947819553316 32.729847595095634\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5870815366506577 0.3917137080570683 30.89164601266384\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  14\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  223 0 0\n",
      "Max Class Size:  235 0 1\n",
      "Max Class Size:  191 0 2\n",
      "Max Class Size:  212 0 3\n",
      "Max Class Size:  183 0 4\n",
      "Max Class Size:  210 0 5\n",
      "Max Class Size:  191 0 6\n",
      "Max Class Size:  202 0 7\n",
      "Max Class Size:  181 0 8\n",
      "Max Class Size:  172 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Base Domain:  223 0 0\n",
      "Base Domain:  235 0 1\n",
      "Base Domain:  191 0 2\n",
      "Base Domain:  212 0 3\n",
      "Base Domain:  183 0 4\n",
      "Base Domain:  210 0 5\n",
      "Base Domain:  191 0 6\n",
      "Base Domain:  202 0 7\n",
      "Base Domain:  181 0 8\n",
      "Base Domain:  172 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  118.31033653020859 113.4003478884697 2221.844625234604\n",
      "Train Acc Env :  68.6\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  23.710737235844135 19.473030153661966 1837.85249710083\n",
      "Train Acc Env :  95.65\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  14.531041920185089 11.880803603678942 1154.5271005630493\n",
      "Train Acc Env :  97.95\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  9.621710658073425 7.079849943518639 719.1210896968842\n",
      "Train Acc Env :  99.1\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  6.696468561887741 4.804591874592006 477.26718378067017\n",
      "Train Acc Env :  99.55\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  5.604593992233276 3.9567197440192103 381.17850947380066\n",
      "Train Acc Env :  99.5\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  4.506150498986244 2.9323491184040904 270.968080163002\n",
      "Train Acc Env :  99.65\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  4.231588810682297 2.476457516197115 222.67788469791412\n",
      "Train Acc Env :  99.65\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  3.099422886967659 1.8907446512021124 168.70875358581543\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.778448700904846 1.6026125121861696 132.85569018125534\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.271706447005272 1.3422902817837894 109.16167950630188\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.8947267979383469 1.2876784317195415 93.17982122302055\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.710696168243885 1.1454234048724174 80.43693432211876\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.6177353113889694 0.9894713475368917 66.08638432621956\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.8153746575117111 1.104004370747134 72.62119036912918\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  14\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Base Domain:  223 0 0\n",
      "Base Domain:  235 0 1\n",
      "Base Domain:  191 0 2\n",
      "Base Domain:  212 0 3\n",
      "Base Domain:  183 0 4\n",
      "Base Domain:  210 0 5\n",
      "Base Domain:  191 0 6\n",
      "Base Domain:  202 0 7\n",
      "Base Domain:  181 0 8\n",
      "Base Domain:  172 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.1052269488573074 0.5132464342168532 135.1519856750965\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.0800195783376694 0.42021324939560145 125.30353319644928\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.48666615784168243 0.2725597383105196 67.6793087720871\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.49164979159832 0.22059121110942215 50.79623790085316\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5369843393564224 0.22482391045195982 44.206853061914444\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5351388603448868 0.2666391379898414 48.12926597893238\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5450791567564011 0.2802581374417059 45.615254029631615\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.4429285079240799 0.2926884714397602 39.05454406142235\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.8679274469614029 0.3945286342059262 47.60654041171074\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5623331367969513 0.4133814631495625 43.12169586122036\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.49974195659160614 0.3489856853848323 34.42697197198868\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.635687991976738 0.4004527577199042 35.555724769830704\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5674013197422028 0.37282689299900085 32.89572539925575\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.6339096799492836 0.4119149602483958 33.691480219364166\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.6076143383979797 0.4323527036467567 33.50475299358368\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  14\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "Max Class Size:  206 0 0\n",
      "Max Class Size:  242 0 1\n",
      "Max Class Size:  182 0 2\n",
      "Max Class Size:  209 0 3\n",
      "Max Class Size:  179 0 4\n",
      "Max Class Size:  194 0 5\n",
      "Max Class Size:  189 0 6\n",
      "Max Class Size:  201 0 7\n",
      "Max Class Size:  198 0 8\n",
      "Max Class Size:  200 0 9\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000]) (10000,)\n",
      "[2000, 2000, 2000, 2000, 2000]\n",
      "torch.Size([10000, 224, 224]) torch.Size([10000, 10]) torch.Size([10000, 5]) (10000,)\n",
      "<class 'torch.Tensor'> torch.Size([100]) torch.Size([100, 1, 28, 28])\n",
      "Source Domain  15\n",
      "Source Domain  30\n",
      "Source Domain  45\n",
      "Source Domain  60\n",
      "Source Domain  75\n",
      "torch.Size([500, 224, 224]) torch.Size([500]) (500,)\n",
      "[100, 100, 100, 100, 100]\n",
      "torch.Size([500, 224, 224]) torch.Size([500, 10]) torch.Size([500, 5]) (500,)\n",
      "<class 'torch.Tensor'> torch.Size([2000]) torch.Size([2000, 1, 28, 28])\n",
      "Source Domain  0\n",
      "Source Domain  90\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000]) (4000,)\n",
      "[2000, 2000]\n",
      "torch.Size([4000, 224, 224]) torch.Size([4000, 10]) torch.Size([4000, 2]) (4000,)\n",
      "Train Domains, Domain Size, BaseDomainIdx, Total Domains:  ['15', '30', '45', '60', '75'] 5 2000 [2000, 2000, 2000, 2000, 2000]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Model Architecture:  resnet18\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Base Domain:  206 0 0\n",
      "Base Domain:  242 0 1\n",
      "Base Domain:  182 0 2\n",
      "Base Domain:  209 0 3\n",
      "Base Domain:  179 0 4\n",
      "Base Domain:  194 0 5\n",
      "Base Domain:  189 0 6\n",
      "Base Domain:  201 0 7\n",
      "Base Domain:  198 0 8\n",
      "Base Domain:  200 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  117.40800823271275 111.85875722020864 2468.44175054878\n",
      "Train Acc Env :  68.3\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  22.689306899905205 19.315591372549534 1890.733941078186\n",
      "Train Acc Env :  95.65\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  11.256707049906254 9.99715487845242 1115.2613525390625\n",
      "Train Acc Env :  98.45\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  8.219497457146645 6.842390699312091 706.9736711978912\n",
      "Train Acc Env :  99.4\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  6.398498460650444 4.674737828783691 503.48386311531067\n",
      "Train Acc Env :  99.55\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  5.294109731912613 3.469221318140626 356.6588008403778\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  3.820928007364273 2.8028271114453673 263.9312815666199\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  4.760935060679913 2.616230772342533 232.20173466205597\n",
      "Train Acc Env :  99.45\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  3.199951872229576 1.891150526702404 168.43521440029144\n",
      "Train Acc Env :  99.8\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.9548507183790207 1.6749630984850228 146.14214074611664\n",
      "Train Acc Env :  99.75\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.7666804492473602 1.3308635815046728 99.64941430091858\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  2.0703560560941696 1.2141836152877659 93.53450694680214\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.6155031472444534 1.0106300474144518 76.10092934966087\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.3291014730930328 0.9138510643970221 64.38368222117424\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.634102538228035 0.8627625969238579 62.81725177168846\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  14\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Base Domain:  206 0 0\n",
      "Base Domain:  242 0 1\n",
      "Base Domain:  182 0 2\n",
      "Base Domain:  209 0 3\n",
      "Base Domain:  179 0 4\n",
      "Base Domain:  194 0 5\n",
      "Base Domain:  189 0 6\n",
      "Base Domain:  201 0 7\n",
      "Base Domain:  198 0 8\n",
      "Base Domain:  200 0 9\n",
      "Total Label MisMatch across pairs:  0\n",
      "torch.Size([2000, 5, 1, 224, 224]) torch.Size([2000, 5, 1])\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.065402403473854 0.4445141439209692 119.27506765723228\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  0\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  1.1241248100996017 0.4332838376285508 136.91679871082306\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  1\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.40273047983646393 0.23522551002679393 57.48633626103401\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  2\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.698445737361908 0.3563984112115577 73.79213535785675\n",
      "Train Acc Env :  99.9\n",
      "Done Training for epoch:  3\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.514292985200882 0.3050006578559987 54.905024349689484\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  4\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.34875452518463135 0.24700364988530055 36.50894612073898\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  5\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.43676480650901794 0.2500679783988744 35.5295572578907\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  6\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.44511713087558746 0.26215388893615454 34.809485509991646\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  7\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5220044255256653 0.2604646092513576 37.317347794771194\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  8\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.6171389818191528 0.2916887692990713 37.76328054070473\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  9\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.555439293384552 0.2826968260342255 33.93698553740978\n",
      "Train Acc Env :  99.95\n",
      "Done Training for epoch:  10\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.4792577028274536 0.34166644321521744 33.70999576151371\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  11\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5716375261545181 0.3870468904497102 33.18966989219189\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  12\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5942870527505875 0.3713860403513536 32.38793042302132\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  13\n",
      "Split Matched Data:  125 torch.Size([16, 5, 1, 224, 224]) 125\n",
      "Train Loss Basic :  0.5545238703489304 0.4202843124512583 33.3951273560524\n",
      "Train Acc Env :  100.0\n",
      "Done Training for epoch:  14\n",
      "\n",
      "\n",
      "Done for the Model..\n",
      "Final Test Accuracy nan nan\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python train.py --dataset rot_mnist --method_name matchdg_ctr --match_case 0.01 --batch_size 128 --match_flag 1\n",
    "python train.py --dataset rot_mnist --method_name matchdg_erm --penalty_ws 0.1 --match_case -1 --ctr_match_case 0.01 --ctr_match_flag 1 --ctr_match_interrupt 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2\n",
    "\n",
    "* ERM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python test.py --dataset rot_mnist --method_name erm_match --match_case 0.01 --penalty_ws 0.0 --test_metric match_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MatchDG (Default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python test.py --dataset rot_mnist --method_name matchdg_ctr --match_case 0.01 --match_flag 1 --test_metric match_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MatchDG (PerfMatch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python test.py --dataset rot_mnist --method_name matchdg_ctr --match_case 0.01 --match_flag 1 --test_metric match_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3\n",
    "\n",
    "* Approx 25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python train.py --dataset rot_mnist --method_name erm_match --match_case 0.25 --penalty_ws 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Approx 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python train.py --dataset rot_mnist --method_name erm_match --match_case 0.50 --penalty_ws 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Approx 75:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python train.py --dataset rot_mnist --method_name erm_match --match_case 0.75 --penalty_ws 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
